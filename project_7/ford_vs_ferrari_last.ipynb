{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install --upgrade pip -q efficientnet\n!pip install git+https://github.com/mjkvaak/ImageDataAugmentor\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport zipfile\nimport csv\nimport sys\nimport os\n\n\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.layers import *\nfrom keras.optimizers import Adam, SGD\n\n\n\nfrom keras.applications.resnet50 import ResNet50 \nfrom keras.preprocessing import image\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\n\nimport efficientnet.keras as efn\nimport tensorflow.keras.models as M\nfrom tensorflow.keras import layers\nimport tensorflow.keras.layers as L\nimport albumentations as albumentations\n\nfrom ImageDataAugmentor.image_data_augmentor import *\nimport albumentations\n\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n#увеличим дефолтный размер графиков\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n#графики в svg выглядят более четкими\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline\n\nprint(os.listdir(\"../input/sf-dl-car-classification\"))\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Setup"},{"metadata":{"trusted":true},"cell_type":"code","source":"# В setup выносим основные настройки: так удобнее их перебирать в дальнейшем.\n\n\nEPOCHS               = 8  # эпох на обучение\nBATCH_SIZE           = 64 # уменьшаем batch если сеть большая, иначе не поместится в память на GPU\nLR                   = 1e-4\n\nCLASS_NUM            = 10  # количество классов в нашей задаче\nIMG_SIZE             = 400 # какого размера подаем изображения в сеть\nIMG_CHANNELS         = 3   # у RGB 3 канала\nVAL_SPLIT            = 0.2\n\n# Learning Rate One Cycle Policy\nMAX_MOMENTUM = 0.98\nBASE_MOMENTUM = 0.85\nCYCLICAL_MOMENTUM = True\nAUGMENT = True\nCYCLES = 2.35\n\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '../input/sf-dl-car-classification/'\nPATH = \"../working/car/\" # рабочая директория\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.makedirs(PATH,exist_ok=True)\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)  \nPYTHONHASHSEED = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(DATA_PATH+\"train.csv\")\nsample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\ntrain_df.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()\nsample_submission.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.Category.value_counts(sort=True).plot(kind = 'barh', figsize=(3,6))\n#данные распределены равномерно","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Распаковываем картинки')\n# Will unzip the files so that you can see them..\nfor data_zip in ['train.zip', 'test.zip']:\n    with zipfile.ZipFile(\"../input/sf-dl-car-classification/\"+data_zip,\"r\") as z:\n        z.extractall(PATH)\n        \nprint(os.listdir(PATH))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Пример картинок (random sample)')\nplt.figure(figsize=(12,8))\n\nrandom_image = train_df.sample(n=9)\nrandom_image_paths = random_image['Id'].values\nrandom_image_cat = random_image['Category'].values\n\nfor index, path in enumerate(random_image_paths):\n    im = PIL.Image.open(PATH+f'train/{random_image_cat[index]}/{path}')\n    plt.subplot(3,3, index+1)\n    plt.imshow(im)\n    plt.title('Class: '+str(random_image_cat[index]))\n    plt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image = PIL.Image.open(PATH+'/train/0/100306.jpg')\nimgplot = plt.imshow(image)\nplt.show()\nimage.size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Аугментация"},{"metadata":{},"cell_type":"markdown","source":"### albumentations"},{"metadata":{"trusted":true},"cell_type":"code","source":"AUGMENTATIONS = albumentations.Compose([\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.Rotate(limit=30, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n    albumentations.OneOf([\n        albumentations.CenterCrop(height=224, width=200),\n        albumentations.CenterCrop(height=200, width=224),\n    ],p=0.5),\n    albumentations.OneOf([\n        albumentations.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=0.5),\n    albumentations.GaussianBlur(p=0.05),\n    albumentations.HueSaturationValue(p=0.5),\n    albumentations.RGBShift(p=0.5),\n    albumentations.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n    albumentations.Resize(IMG_SIZE, IMG_SIZE)\n])\n\ntrain_datagen = ImageDataAugmentor(\n        rescale=1./255,\n        augment = AUGMENTATIONS,\n        validation_split=VAL_SPLIT,\n        )\n        \ntest_datagen = ImageDataAugmentor(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ImageDataGenerator"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    rotation_range = 30,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    brightness_range = [0.5 ,1.5],\n    validation_split=VAL_SPLIT, # set validation split\n    horizontal_flip=False)\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Генерируем новые данные"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    PATH+'train/',      # директория где расположены папки с картинками \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data\n\ntest_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model\n### Решение с использованием сетей EfficientNetB6, EfficientNetB7 с заморозкой слоев, finetuning, CLR, OCP \n### используем стандартные веса 'imagenet' и веса 'noisy-student'"},{"metadata":{"trusted":true},"cell_type":"code","source":"### CLR and OCP","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Implement cyclical learning rate policy Algorithm \nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras import backend as K\n\nclass CyclicLR(Callback):\n    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n    The method cycles the learning rate between two boundaries with\n    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n    The amplitude of the cycle can be scaled on a per-iteration or \n    per-cycle basis.\n    This class has three built-in policies, as put forth in the paper.\n    \"triangular\":\n        A basic triangular cycle w/ no amplitude scaling.\n    \"triangular2\":\n        A basic triangular cycle that scales initial amplitude by half each cycle.\n    \"exp_range\":\n        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n        cycle iteration.\n    For more detail, please see paper.\n    \n    # Example\n        ```python\n            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n                                step_size=2000., mode='triangular')\n            model.fit(X_train, Y_train, callbacks=[clr])\n        ```\n    \n    Class also supports custom scaling functions:\n        ```python\n            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n                                step_size=2000., scale_fn=clr_fn,\n                                scale_mode='cycle')\n            model.fit(X_train, Y_train, callbacks=[clr])\n        ```    \n    # Arguments\n        base_lr: initial learning rate which is the\n            lower boundary in the cycle.\n        max_lr: upper boundary in the cycle. Functionally,\n            it defines the cycle amplitude (max_lr - base_lr).\n            The lr at any cycle is the sum of base_lr\n            and some scaling of the amplitude; therefore \n            max_lr may not actually be reached depending on\n            scaling function.\n        step_size: number of training iterations per\n            half cycle. Authors suggest setting step_size\n            2-8 x training iterations in epoch.\n        mode: one of {triangular, triangular2, exp_range}.\n            Default 'triangular'.\n            Values correspond to policies detailed above.\n            If scale_fn is not None, this argument is ignored.\n        gamma: constant in 'exp_range' scaling function:\n            gamma**(cycle iterations)\n        scale_fn: Custom scaling policy defined by a single\n            argument lambda function, where \n            0 <= scale_fn(x) <= 1 for all x >= 0.\n            mode paramater is ignored \n        scale_mode: {'cycle', 'iterations'}.\n            Defines whether scale_fn is evaluated on \n            cycle number or cycle iterations (training\n            iterations since start of cycle). Default is 'cycle'.\n    \"\"\"\n\n    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n                 gamma=1., scale_fn=None, scale_mode='cycle'):\n        super(CyclicLR, self).__init__()\n\n        self.base_lr = base_lr\n        self.max_lr = max_lr\n        self.step_size = step_size\n        self.mode = mode\n        self.gamma = gamma\n        if scale_fn == None:\n            if self.mode == 'triangular':\n                self.scale_fn = lambda x: 1.\n                self.scale_mode = 'cycle'\n            elif self.mode == 'triangular2':\n                self.scale_fn = lambda x: 1/(2.**(x-1))\n                self.scale_mode = 'cycle'\n            elif self.mode == 'exp_range':\n                self.scale_fn = lambda x: gamma**(x)\n                self.scale_mode = 'iterations'\n        else:\n            self.scale_fn = scale_fn\n            self.scale_mode = scale_mode\n        self.clr_iterations = 0.\n        self.trn_iterations = 0.\n        self.history = {}\n\n        self._reset()\n\n    def _reset(self, new_base_lr=None, new_max_lr=None,\n               new_step_size=None):\n        \"\"\"Resets cycle iterations.\n        Optional boundary/step size adjustment.\n        \"\"\"\n        if new_base_lr != None:\n            self.base_lr = new_base_lr\n        if new_max_lr != None:\n            self.max_lr = new_max_lr\n        if new_step_size != None:\n            self.step_size = new_step_size\n        self.clr_iterations = 0.\n        \n    def clr(self):\n        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n        if self.scale_mode == 'cycle':\n            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n        else:\n            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n        \n    def on_train_begin(self, logs={}):\n        logs = logs or {}\n\n        if self.clr_iterations == 0:\n            K.set_value(self.model.optimizer.lr, self.base_lr)\n        else:\n            K.set_value(self.model.optimizer.lr, self.clr())        \n            \n    def on_batch_end(self, epoch, logs=None):\n        \n        logs = logs or {}\n        self.trn_iterations += 1\n        self.clr_iterations += 1\n\n        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n        self.history.setdefault('iterations', []).append(self.trn_iterations)\n\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)\n        \n        K.set_value(self.model.optimizer.lr, self.clr())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Implement One Cycle Policy Algorithm in the Keras Callback Class\n\nimport keras\nfrom sklearn.metrics import log_loss, roc_auc_score, accuracy_score\nfrom keras.losses import binary_crossentropy\nfrom keras.metrics import binary_accuracy\nfrom keras import backend as K\nfrom keras.callbacks import *\n\nclass OneCyclicP(keras.callbacks.Callback):\n    \n    def __init__(self,base_lr, max_lr, step_size, base_m, max_m, cyclical_momentum):\n \n        self.base_lr = base_lr\n        self.max_lr = max_lr\n        self.base_m = base_m\n        self.max_m = max_m\n        self.cyclical_momentum = cyclical_momentum\n        self.step_size = step_size\n        \n        self.clr_iterations = 0.\n        self.cm_iterations = 0.\n        self.trn_iterations = 0.\n        self.history = {}\n        \n    def clr(self):\n        \n        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n        \n        if cycle == 2:\n            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)          \n            return self.base_lr-(self.base_lr-self.base_lr/100)*np.maximum(0,(1-x))\n        \n        else:\n            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0,(1-x))\n    \n    def cm(self):\n        \n        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n        \n        if cycle == 2:\n            \n            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1) \n            return self.max_m\n        \n        else:\n            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n            return self.max_m - (self.max_m-self.base_m)*np.maximum(0,(1-x))\n        \n        \n    def on_train_begin(self, logs={}):\n        logs = logs or {}\n\n        if self.clr_iterations == 0:\n            K.set_value(self.model.optimizer.lr, self.base_lr)\n        else:\n            K.set_value(self.model.optimizer.lr, self.clr())\n            \n        if self.cyclical_momentum == True:\n            if self.clr_iterations == 0:\n                K.set_value(self.model.optimizer.momentum, self.cm())\n            else:\n                K.set_value(self.model.optimizer.momentum, self.cm())\n            \n            \n    def on_batch_begin(self, batch, logs=None):\n        \n        logs = logs or {}\n        self.trn_iterations += 1\n        self.clr_iterations += 1\n\n        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n        self.history.setdefault('iterations', []).append(self.trn_iterations)\n        \n        if self.cyclical_momentum == True:\n            self.history.setdefault('momentum', []).append(K.get_value(self.model.optimizer.momentum))\n\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)\n        \n        K.set_value(self.model.optimizer.lr, self.clr())\n        \n        if self.cyclical_momentum == True:\n            K.set_value(self.model.optimizer.momentum, self.cm())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install keras-one-cycle-lr\n#import tensorflow.keras as keras\n#import tensorflow.keras.layers as layers\n#import tensorflow.keras.backend as K\n#import keras_one_cycle_clr as ktool\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#base_model = efn.EfficientNetB6(weights='noisy-student', include_top=False, input_shape = input_shape)\n\n#base_model = efn.EfficientNetB6(weights='imagenet', include_top=False, input_shape = input_shape)\n\nbase_model = efn.EfficientNetB7(weights='imagenet', include_top=False, input_shape = input_shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.summary()\nprint(len(base_model.layers))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#всего 659(B6)/806(B7) слоев, заморозим все веса сети\nbase_model.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# устанавливаем \"голову\"\nmodel_iter = M.Sequential()\nmodel_iter.add(base_model)\nmodel_iter.add(L.GlobalAveragePooling2D())\nmodel_iter.add(L.BatchNormalization()) # batch normalisation\nmodel_iter.add(L.Dense(256, activation='relu'))\nmodel_iter.add(L.Dropout(0.25)) # обязательно для предупреждения переобучения\nmodel_iter.add(L.Dense(CLASS_NUM, activation='softmax'))\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = EPOCHS\nmax_lr = 0.001\nbase_lr = max_lr/10\nmax_m = 0.98\nbase_m = 0.85\n\ncyclical_momentum = True\naugment = True\ncycles = 2.35\n\n# Расчет количества итерация и шага изменения learning rate\niterations = round(train_generator.samples//train_generator.batch_size*epochs)\niterations = list(range(0,iterations+1))\nstep_size = len(iterations)/(cycles)\n\nmodel_iter.compile(loss='binary_crossentropy', optimizer=SGD(0.0000001), metrics=['accuracy'])\n\nclr = CyclicLR(base_lr=0.001, max_lr=0.006,step_size=4000., mode='triangular')\n\n#clr =  OneCyclicP(base_lr=base_lr,max_lr=max_lr,\n#    step_size=step_size,max_m=0.98,\n#    base_m=base_m,cyclical_momentum=cyclical_momentum\n#)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_iter.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ModelCheckpoint для сохранения прогресса обучения модели(потом подгрузим для дообучения модель)    \n\ncheckpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\ncallbacks_list = [checkpoint, earlystop]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model_iter.fit_generator(\n    train_generator,\n    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n    validation_data = test_generator, \n    validation_steps = test_generator.samples//test_generator.batch_size,\n    epochs = 9,\n    callbacks = callbacks_list\n    )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_iter.save('../working/model_last.hdf5')\nmodel_iter.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model_iter.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Finetuning. Step1(\"разморозка\"  слоев EfficientNetB6/B7)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(model_iter.layers))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_iter.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = True\nfine_tune_at = 400\n\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE           = 32\nIMG_SIZE             = 300\n\n\nAUGMENTATIONS = albumentations.Compose([\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.Rotate(limit=30, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n    albumentations.OneOf([\n        albumentations.CenterCrop(height=224, width=200),\n        albumentations.CenterCrop(height=200, width=224),\n    ],p=0.5),\n    albumentations.OneOf([\n        albumentations.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=0.5),\n    albumentations.GaussianBlur(p=0.05),\n    albumentations.HueSaturationValue(p=0.5),\n    albumentations.RGBShift(p=0.5),\n    albumentations.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n    albumentations.Resize(IMG_SIZE, IMG_SIZE)\n])\n\ntrain_datagen = ImageDataAugmentor(\n        rescale=1./255,\n        augment = AUGMENTATIONS,\n        validation_split=VAL_SPLIT,\n        )\n        \ntest_datagen = ImageDataAugmentor(rescale=1./255)\n\n\ntrain_generator = train_datagen.flow_from_directory(\n    PATH+'train/',      # директория где расположены папки с картинками \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data\n\ntest_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_lr = 0.0001\nbase_lr = max_lr/10\n\nmax_m = 0.98\nbase_m = 0.85\n\ncyclical_momentum = True\naugment = True\ncycles = 2.35\n\n# Расчет количества итерация и шага изменения learning rate\niterations = round(train_generator.samples//train_generator.batch_size*epochs)\niterations = list(range(0,iterations+1))\nstep_size = len(iterations)/(cycles)\n\nmodel_iter.compile(loss='binary_crossentropy', optimizer=SGD(0.0000001), metrics=['accuracy'])\n\nclr = CyclicLR(base_lr=0.0001, max_lr=0.0009,step_size=6000., mode='triangular')\n\n#clr =  OneCyclicP(base_lr=base_lr,max_lr=max_lr,\n#    step_size=step_size,max_m=0.98,\n#    base_m=base_m,cyclical_momentum=cyclical_momentum)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LR = 0.00001\n\nmodel_iter.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ModelCheckpoint для сохранения прогресса обучения модели(потом подгрузим для дообучения модель)    \n\ncheckpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\ncallbacks_list = [checkpoint, earlystop]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model_iter.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model_iter.fit_generator(\n        train_generator,\n        steps_per_epoch = len(train_generator),\n        validation_data = test_generator, \n        validation_steps = len(test_generator),\n        epochs = 8,\n        callbacks = callbacks_list\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_iter.save('../working/model_last.hdf5')\nmodel_iter.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model_iter.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Finetuning. Step2(\"Заморозка\" слоев EfficientNetB6/B7). Уменьшаем learning rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = True\nfine_tune_at = 300\n\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LR = 0.000001\nmodel_iter.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])\n\ncheckpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\ncallbacks_list = [checkpoint, earlystop]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model_iter.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#EPOCHS               = 7\n#BATCH_SIZE           = 32\n#IMG_SIZE             = 196\n\nhistory = model_iter.fit_generator(\n        train_generator,\n        steps_per_epoch = len(train_generator),\n        validation_data = test_generator, \n        validation_steps = len(test_generator),\n        epochs = 8,# можно 8\n        callbacks = callbacks_list\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_iter.save('../working/model_last.hdf5')\nmodel_iter.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model_iter.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ### Finetuning. Step3(итерационная \"зморозка\"  слоев EfficientNetB6/B7)"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = False\n\nfine_tune_at = 200\n\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable = False\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#BATCH_SIZE = 32\n#IMG_SIZE             = 400\n\n\nAUGMENTATIONS = albumentations.Compose([\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.Rotate(limit=30, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n    albumentations.OneOf([\n        albumentations.CenterCrop(height=224, width=200),\n        albumentations.CenterCrop(height=200, width=224),\n    ],p=0.5),\n    albumentations.OneOf([\n        albumentations.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=0.5),\n    albumentations.GaussianBlur(p=0.05),\n    albumentations.HueSaturationValue(p=0.5),\n    albumentations.RGBShift(p=0.5),\n    albumentations.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n    albumentations.Resize(IMG_SIZE, IMG_SIZE)\n])\n\ntrain_datagen = ImageDataAugmentor(\n        rescale=1./255,\n        augment = AUGMENTATIONS,\n        validation_split=VAL_SPLIT,\n        )\n        \ntest_datagen = ImageDataAugmentor(rescale=1./255)\n\n\ntrain_generator = train_datagen.flow_from_directory(\n    PATH+'train/',      # директория где расположены папки с картинками \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data\n\ntest_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LR = 0.000001\nmodel_iter.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\ncallbacks_list = [checkpoint, earlystop]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model_iter.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model_iter.fit_generator(\n        train_generator,\n        steps_per_epoch = len(train_generator),\n        validation_data = test_generator, \n        validation_steps = len(test_generator),\n        epochs = 8,\n        callbacks = callbacks_list\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_iter.save('../working/model_last.hdf5')\nmodel_iter.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model_iter.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Используем ранее полученные веса модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 32\n#IMG_SIZE             = 300\n\n\nAUGMENTATIONS = albumentations.Compose([\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.Rotate(limit=30, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n    albumentations.OneOf([\n        albumentations.CenterCrop(height=224, width=200),\n        albumentations.CenterCrop(height=200, width=224),\n    ],p=0.5),\n    albumentations.OneOf([\n        albumentations.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=0.5),\n    albumentations.GaussianBlur(p=0.05),\n    albumentations.HueSaturationValue(p=0.5),\n    albumentations.RGBShift(p=0.5),\n    albumentations.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n    albumentations.Resize(IMG_SIZE, IMG_SIZE)\n])\n\ntrain_datagen = ImageDataAugmentor(\n        rescale=1./255,\n        augment = AUGMENTATIONS,\n        validation_split=VAL_SPLIT,\n        )\n        \ntest_datagen = ImageDataAugmentor(rescale=1./255)\n\n\ntrain_generator = train_datagen.flow_from_directory(\n    PATH+'train/',      # директория где расположены папки с картинками \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data\n\ntest_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nbase_model.trainable = False\n\nfine_tune_at = 50\n\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable = False\n    \nLR = 0.0000001\nmodel_iter.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])\n\ncheckpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\ncallbacks_list = [checkpoint, earlystop]\n   \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model_iter.load_weights('best_model.hdf5') # Подгружаем ранее обученные веса\n\n#callbacks_list = [checkpoint, earlystop]\n\n# Обучаем\n\nhistory = model_iter.fit_generator(\n        train_generator,\n        steps_per_epoch = len(train_generator),\n        validation_data = test_generator, \n        validation_steps = len(test_generator),\n        epochs = 6,\n        callbacks = callbacks_list\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model_iter.fit_generator(\n        train_generator,\n        steps_per_epoch = len(train_generator),\n        validation_data = test_generator, \n        validation_steps = len(test_generator),\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model_iter.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sub_generator.samples","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sub_generator.reset()\npredictions = model_iter.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1) \npredictions = np.argmax(predictions, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload/','')\nsubmission.to_csv('submission.csv', index=False)\nprint('Save submit')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test Time Augmentation\n#### попробуем \"предложить\" модели модифицированные тестовые изображения, сделаем несоклько раз и усредним результат "},{"metadata":{"trusted":true},"cell_type":"code","source":"AUGMENTATIONS = albumentations.Compose([\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.Rotate(limit=30, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n    albumentations.OneOf([\n        albumentations.CenterCrop(height=250, width=200),\n        albumentations.CenterCrop(height=200, width=250),\n    ],p=0.5),\n    albumentations.OneOf([\n        albumentations.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=0.5),\n    albumentations.GaussianBlur(p=0.05),\n    albumentations.HueSaturationValue(p=0.5),\n    albumentations.RGBShift(p=0.5),\n    albumentations.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n    albumentations.Resize(IMG_SIZE, IMG_SIZE)\n])\n      \ntest_datagen = ImageDataAugmentor( \n    rescale=1./255,\n    augment = AUGMENTATIONS,\n    validation_split=VAL_SPLIT,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tta_steps = 10 # берем среднее из 10 предсказаний\npredictions = []\n\nfor i in range(tta_steps):\n    preds = model_iter.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1) \n    predictions.append(preds)\n\npred = np.mean(predictions, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = np.argmax(pred, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload/','')\nsubmission.to_csv('submission_TTA.csv', index=False)\nprint('Save submit')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Выводы"},{"metadata":{},"cell_type":"markdown","source":"План работ.\n1. \tEDA\n2.\tСтроим модель на baseline решении.\n3.\tИспользуем Sota решения(FixEfficientNet-B6/B7) \n4.\tИспользуем fietuning перенос обучения\n5.\tИспользуем аргументацию на основе Albumentations, ImageDataGenerator.\n6.\tИспользуем функцию callback с ранее полученными оптимальными весами слоев сети.\n7.\tИспользуем разные варианты настройки гиперпараметров: размер изображений,  размер batch слоев.\n8.  Используем используем оптимизацию LR - CLR, OCP.\n9.\tИспользуем разные настройки «головы»(меняем нелинейность модели, используя ‘elu’), включая batch нормализацию\n10.\tВыводим модель в prodaction.(не удалось реализовать)\n\nРезультат работы, выводы.\n\n\nТаблица значений метрики accuracy в зависимости от применяемого метода построения модели.\n\n   Модель\t            Аугментация\t       Batch\tFrozenLayer\t  ImageSize\t  Batchnorm\t  ValueMetric\n1. BaseLine\t            ImageDataGenerator\t32\t    No\t          256\t              No\t93\n2. FixEfficientNet-B6\tImageDataGenerator\t32\t    Yes\t          128\t              No\t94,6\n3. FixEfficientNet-B6\tImageDataGenerator\t32\t    Yes\t          256\t              No\t96\n4. FixEfficientNet-B6\tAlbumentations\t    32\t    Yes\t          256\t             Yes\t96,22\n5. FixEfficientNet-B7   Albumentations      64      Yes           224-400            Yes    96,04\n\nИспользовал EfficientNetB6/B7 с 'noisy-student', ТТА, CLR/OCP оптимизацию LR.  Указнные методы не принесли существеннго прироста метрики.\nУлучшение метрики  за счет увеличения batchsize и размера картинки получить не удалось.\nВозможно  надо еще попробовать поменять параметры Albumentations.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}